script({
    title: "generate impact assessment using queries",
    description: "Generate an impact assessment for a given project usign queries.",
    categories: ["impact assessment"],
})

def("README", env.files.filter((f) => f.filename.endsWith("README.md")))
def("DIRECTIONS", env.files.filter((f) => f.filename.endsWith("how-to.md")))
def("TEMPLATE", env.files.filter((f) => f.filename.endsWith("template.md")))

const pdfs = env.files.filter((f) => f.filename.endsWith(".pdf"))
console.log("pdf files: ", pdfs)

def(
    "GOAL",
    await retreival.query("What is the goal of the project, and how is it described in plain language?", {
        files: pdfs,
    })
)

def(
    "RELATION",
    await retreival.query("How does this project relate to any Microsoft systems or products?", {
        files: pdfs,
    })
)

def(
    "ASSETS",
    await retreival.query("What assets are you planning to share (e.g., demo, source code, models, data)?", {
        files: pdfs,
    })
)

def(
    "RECIPIENTS",
    await retreival.query("Who are the intended recipients of the shared assets (e.g., Open Source/Public, partners, product teams)?", {
        files: pdfs,
    })
)

def(
    "SHARING_GOALS",
    await retreival.query("What are the goals for sharing these assets?", {
        files: pdfs,
    })
)

def(
    "DATA_IMPACT",
    await retreival.query("What are the top impacts that the makeup of your data could have on your work?", {
        files: pdfs,
    })
)

def(
    "LIMITATIONS",
    await retreival.query("What are the current limitations of the system, including scenarios where it may not perform well?", {
        files: pdfs,
    })
)

def(
    "MALICIOUS_USE",
    await retreival.query("If a malicious entity were to use the assets you share, what could happen? What are the most obvious abuse scenarios?", {
        files: pdfs,
    })
)

def(
    "MISUSE",
    await retreival.query("Is it possible for your assets to be misused unintentionally? If so, how?", {
        files: pdfs,
    })
)

def(
    "MITIGATIONS",
    await retreival.query("What mitigations do you intend to use for risks identified?", {
        files: pdfs,
    })
)

def(
    "REAL_USES",
    await retreival.query("What are the most likely real-world uses of the research project?", {
        files: pdfs,
    })
)

def(
    "REAL_MISUSES",
    await retreival.query("What are the most likely real-world misuses of the research project?", {
        files: pdfs,
    })
)

def(
    "STAKEHOLDERS",
    await retreival.query("Who are the possible stakeholders that would be most impacted by both your research and the future real-world uses?", {
        files: pdfs,
    })
)

def(
    "USE_CASES",
    await retreival.query("What are the intended use cases for this work?", {
        files: pdfs,
    })
)

def(
    "SUITABILITY",
    await retreival.query("Which use cases and stakeholders is this work best suited for, and why?", {
        files: pdfs,
    })
)

def(
    "HARMS",
    await retreival.query("After reflecting on your real-world use cases, stakeholders, and data, what are the anticipated harms to stakeholders and how can the identified harms be mitigated?", {
        files: pdfs,
    })
)

def(
    "DIVERSITY",
    await retreival.query("How will the project impact the diversity and inclusivity of AI technology?", {
        files: pdfs,
    })
)

def(
    "PRIVACY_SECURITY",
    await retreival.query("What measures are in place to ensure the privacy and security of data used or generated by the project?", {
        files: pdfs,
    })
)

def(
    "ETHICAL_MONITORING",
    await retreival.query("How will the project's outcomes be monitored for long-term ethical implications and societal impact?", {
        files: pdfs,
    })
)

def(
    "FEEDBACK",
    await retreival.query("What processes are in place for stakeholders to provide feedback or raise concerns about the project's impact?", {
        files: pdfs,
    })
)

def(
    "AI_PRINCIPLES",
    await retreival.query("How does the project align with Microsoft's overall Responsible AI principles and strategies?", {
        files: pdfs,
    })
)

def(
    "ENVIRONMENT",
    await retreival.query("Are there any environmental impacts associated with the deployment or operation of the project's technology?", {
        files: pdfs,
    })
)

def(
    "TRUST",
    await retreival.query("How will the project contribute to or detract from the public's trust in AI?", {
        files: pdfs,
    })
)

def(
    "EMPLOYMENT",
    await retreival.query("What are the potential impacts on employment and the workforce due to the project's technology?", {
        files: pdfs,
    })
)

def(
    "BIAS",
    await retreival.query("How will the project address potential biases in AI algorithms and decision-making processes?", {
        files: pdfs,
    })
)

def(
    "REVISION",
    await retreival.query("What is the plan for ongoing review and revision of the impact assessment as the project evolves?", {
        files: pdfs,
    })
)

const outputName = "assessment-draft-queries.md"

// use $ to output formatted text to the prompt
$`You are a helpful assistant. Your goal is to write a draft 
responsible AI impact assessment for the project.
Answers to important questions about the project are documented in
GOAL, RELATION, ASSETS, RECIPIENTS, SHARING_GOALS, DATA_IMPACT, 
LIMITATIONS, MALICIOUS_USE, MISUSE, MITIGATIONS, REAL_USES, REAL_MISUSES, 
STAKEHOLDERS, USE_CASES, SUITABILITY, HARMS, DIVERSITY, PRIVACY_SECURITY, 
ETHICAL_MONITORING, FEEDBACK, AI_PRINCIPLES, ENVIRONMENT, TRUST, EMPLOYMENT, 
BIAS, REVISION.
Use the DIRECTIONS and README for guidance in writing the assessment.
**Be sure** that the draft assessment follows the structure and questions in TEMPLATE.
Write the draft assessment to the file ${outputName}.`
