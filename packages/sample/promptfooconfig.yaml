# This configuration compares LLM output of 2 prompts x 2 GPT models across 3 test cases.
# Learn more: https://promptfoo.dev/docs/configuration/guide
description: 'My first eval'

prompts:
  - './src/questions.md'

providers:
  - './src/promptfoo-api-provider.mjs'

defaultTest:
  assert:
    - type: llm-rubric
      value: mentions Markdown
    - type: factuality
      value: Markdown is a text-based syntax to describe documents.
tests:
  - vars:
      script: summarize
      spec: src/rag/markdown.md
  - vars:
      script: summarize
      spec: src/rag/Document.docx
