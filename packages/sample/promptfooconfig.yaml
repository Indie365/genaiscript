# This configuration compares LLM output of 2 prompts x 2 GPT models across 3 test cases.
# Learn more: https://promptfoo.dev/docs/configuration/guide
description: 'My first eval'

prompts:
  - file://./src/run.mjs

providers:
  - id: azureopenai:chat:gpt-4
    config:
      apiHost: 'tnrllmproxy.azurewebsites.net'

defaultTest:
  options:
    provider:
      id: azureopenai:chat:gpt-4
      config:
        apiHost: 'tnrllmproxy.azurewebsites.net'
tests:
  - vars:
      script: summarize
      spec: src/rag/markdown.md
  - vars:
      script: summarize
      spec: src/rag/Document.docx
